import streamlit as st
import pandas as pd
import plotly.express as px
import requests
import json
import unicodedata
import re

# Substitua pela URL RAW correta do seu arquivo CSV no GitHub
GITHUB_CSV_URL = 'https://raw.githubusercontent.com/calazansiesb/CIADM1A/main/GALINACEOS.csv'

# URL para o arquivo GeoJSON dos estados do Brasil (exemplo)
GEOJSON_BR_STATES_URL = 'https://raw.githubusercontent.com/codeforamerica/click_that_hood/master/public/data/brazil-states.geojson'

# --- Defini√ß√£o das vari√°veis e seus nomes de exibi√ß√£o ---
DATA_VARS = {
    'E_CRIA_GAL': {
        'column_name': 'E_CRIA_GAL',
        'display_title': 'Estabelecimentos de Cria√ß√£o de Galin√°ceos',
        'y_axis_label': 'N√∫mero de Estabelecimentos'
    },
    'E_OVOS_PROD': {
        'column_name': 'E_OVOS_PROD',
        'display_title': 'Estabelecimentos de Produ√ß√£o de Ovos',
        'y_axis_label': 'N√∫mero de Estabelecimentos'
    },
    'GAL_TOTAL': {
        'column_name': 'GAL_TOTAL',
        'display_title': 'Total de Galin√°ceos (Cabe√ßas)',
        'y_axis_label': 'Total de Cabe√ßas'
    }
}

# Fun√ß√£o auxiliar para normalizar nomes (remover acentos e converter para min√∫sculas)
def normalize_state_name(name):
    if isinstance(name, str):
        normalized = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode('utf-8')
        return normalized.strip().lower()
    return name

@st.cache_data # Usar st.cache_data para cache de dados
def load_data(url):
    try:
        # Tentar ler com delimitador ';' e ponto como separador de milhares
        df = pd.read_csv(url, sep=';', encoding='latin1', thousands='.')

        # --- CONVERS√ÉO NUM√âRICA ROBUSTA PARA AS COLUNAS DE DADOS ---
        for col_key, info in DATA_VARS.items():
            col_name = info['column_name']
            if col_name in df.columns:
                # Converte para string para garantir manipula√ß√£o de texto
                # Remove pontos (separadores de milhares)
                # Substitui v√≠rgulas (se usadas como decimal) por pontos (para pd.to_numeric)
                df[col_name] = df[col_name].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)
                # Converte para num√©rico, valores inv√°lidos viram NaN
                df[col_name] = pd.to_numeric(df[col_name], errors='coerce')
                # Preenche NaN com 0 (ou outro valor apropriado, dependendo do contexto)
                df[col_name] = df[col_name].fillna(0)
                # Converte para inteiro, pois s√£o contagens/totais
                df[col_name] = df[col_name].astype(int)

        return df
    except FileNotFoundError:
        st.error("Erro: O arquivo n√£o foi encontrado na URL especificada. Verifique se a URL est√° correta e o arquivo existe.")
        return pd.DataFrame()
    except pd.errors.EmptyDataError:
        st.error("Erro: O arquivo est√° vazio. N√£o h√° dados para processar.")
        return pd.DataFrame()
    except pd.errors.ParserError as e:
        st.error(f"Erro: O arquivo CSV n√£o p√¥de ser analisado. Verifique o delimitador (sep=';'), a codifica√ß√£o (encoding='latin1') ou os separadores de n√∫meros (thousands='.'). Detalhes: {e}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"Erro ao carregar dados do GitHub. Verifique a URL ou o formato do arquivo. Detalhes: {e}")
        return pd.DataFrame()

@st.cache_data # Cache para o GeoJSON
def load_geojson(url):
    try:
        response = requests.get(url)
        response.raise_for_status() # Lan√ßa um erro para status HTTP ruins (4xx ou 5xx)
        geojson_data = response.json()

        # Normaliza os nomes dos estados dentro do GeoJSON para facilitar o matching
        for feature in geojson_data['features']:
            if 'name' in feature['properties']:
                feature['properties']['name_original'] = feature['properties']['name']
                feature['properties']['name_normalized'] = normalize_state_name(feature['properties']['name'])
        return geojson_data
    except Exception as e:
        st.error(f"Erro ao carregar o arquivo GeoJSON: {e}. Verifique a URL ou o formato do arquivo.")
        return None

# Carregamento dos dados
df = load_data(GITHUB_CSV_URL)
geojson_data = load_geojson(GEOJSON_BR_STATES_URL)

if df.empty:
    st.warning("N√£o foi poss√≠vel carregar os dados. Verifique a URL e o conte√∫do do arquivo CSV.")
    st.stop()

if geojson_data is None:
    st.warning("N√£o foi poss√≠vel carregar os dados geogr√°ficos. O mapa n√£o ser√° exibido.")


# Verifique as colunas essenciais
required_columns = ['NOM_TERR'] + [v['column_name'] for k, v in DATA_VARS.items()]
for col in required_columns:
    if col not in df.columns:
        st.error(f"A coluna '{col}' n√£o foi encontrada no DataFrame. Por favor, verifique o nome da coluna no seu CSV.")
        st.stop()

# --- Normaliza√ß√£o da coluna NOM_TERR no DataFrame ---
df['NOM_TERR_NORMALIZED'] = df['NOM_TERR'].apply(normalize_state_name)


st.header('üåé An√°lise de Galin√°ceos ‚Äî Explore 3 M√©tricas por Regi√£o ou Nacional')

# Lista oficial dos 26 estados + DF
estados_brasil = [
    'Acre', 'Alagoas', 'Amap√°', 'Amazonas', 'Bahia', 'Cear√°', 'Distrito Federal', 'Esp√≠rito Santo', 'Goi√°s',
    'Maranh√£o', 'Mato Grosso', 'Mato Grosso do Sul', 'Minas Gerais', 'Par√°', 'Para√≠ba', 'Paran√°', 'Pernambuco',
    'Piau√≠', 'Rio de Janeiro', 'Rio Grande do Norte', 'Rio Grande do Sul', 'Rond√¥nia', 'Roraima', 'Santa Catarina',
    'S√£o Paulo', 'Sergipe', 'Tocantins'
]

# Normaliza a lista de estados para a filtragem consistente
normalized_estados_brasil = [normalize_state_name(estado) for estado in estados_brasil]

# Mapeamento de estados para regi√µes
regioes_estados = {
    'Norte': ['Acre', 'Amap√°', 'Amazonas', 'Par√°', 'Rond√¥nia', 'Roraima', 'Tocantins'],
    'Nordeste': ['Alagoas', 'Bahia', 'Cear√°', 'Maranh√£o', 'Para√≠ba', 'Pernambuco', 'Piau√≠', 'Rio Grande do Norte', 'Sergipe'],
    'Centro-Oeste': ['Distrito Federal', 'Goi√°s', 'Mato Grosso', 'Mato Grosso do Sul'],
    'Sudeste': ['Esp√≠rito Santo', 'Minas Gerais', 'Rio de Janeiro', 'S√£o Paulo'],
    'Sul': ['Paran√°', 'Rio Grande do Sul', 'Santa Catarina']
}

# Inverter o dicion√°rio para mapear estado normalizado -> regi√£o
estado_para_regiao_normalized = {normalize_state_name(estado): regiao for regiao, estados in regioes_estados.items() for estado in estados}

# Adicionar 'Regiao' ao DataFrame principal (usando o nome normalizado para o mapeamento de regi√£o)
df['Regiao'] = df['NOM_TERR_NORMALIZED'].map(estado_para_regiao_normalized)

# Filtrar apenas estados do Brasil (usando a coluna normalizada e a lista normalizada)
df_uf = df[df['NOM_TERR_NORMALIZED'].isin(normalized_estados_brasil)].copy()

# --- Seletor de Vari√°vel ---
st.subheader('Selecione a M√©trica para An√°lise:')
selected_metric_key = st.selectbox(
    'Escolha a m√©trica',
    options=list(DATA_VARS.keys()),
    format_func=lambda x: DATA_VARS[x]['display_title']
)
selected_metric_info = DATA_VARS[selected_metric_key]
selected_column = selected_metric_info['column_name']
selected_display_title = selected_metric_info['display_title']
selected_y_label = selected_metric_info['y_axis_label']


# Calcular a SOMA da m√©trica selecionada por UF (para o Brasil inteiro)
freq_data_por_uf_total = df_uf.groupby('NOM_TERR')[selected_column].sum().sort_values(ascending=False)
df_plot_total = freq_data_por_uf_total.rename_axis('Unidade Federativa').reset_index(name=selected_y_label)


# === Seletor de Regi√£o para os Gr√°ficos Din√¢micos ===
st.subheader('Selecione a Regi√£o para Exibir nos Gr√°ficos:')
regioes_disponiveis = ['Todas as Regi√µes'] + list(regioes_estados.keys())
selected_region = st.selectbox('Escolha uma regi√£o', regioes_disponiveis)

# Filtragem e c√°lculo da m√©trica com base na sele√ß√£o
df_filtered_by_region = df_uf.copy()

title_sufix = ''
if selected_region != 'Todas as Regi√µes':
    estados_da_regiao = regioes_estados[selected_region]
    normalized_estados_da_regiao = [normalize_state_name(e) for e in estados_da_regiao]
    df_filtered_by_region = df_filtered_by_region[df_filtered_by_region['NOM_TERR_NORMALIZED'].isin(normalized_estados_da_regiao)]
    title_sufix = f' na Regi√£o {selected_region}'

# Calcular a SOMA da m√©trica selecionada APENAS para os estados filtrados
if not df_filtered_by_region.empty:
    freq_data_por_uf_filtered = df_filtered_by_region.groupby('NOM_TERR')[selected_column].sum().sort_values(ascending=False)
    df_plot_filtered = freq_data_por_uf_filtered.rename_axis('Unidade Federativa').reset_index(name=selected_y_label)
    # Adiciona a coluna normalizada para o matching no mapa
    df_plot_filtered['Unidade Federativa_Normalized_for_map'] = df_plot_filtered['Unidade Federativa'].apply(normalize_state_name)
else:
    df_plot_filtered = pd.DataFrame(columns=['Unidade Federativa', selected_y_label, 'Unidade Federativa_Normalized_for_map'])


# === Gr√°fico Din√¢mico de Distribui√ß√£o por UF (Barras) ===
st.subheader(f'{selected_display_title} por Estado{title_sufix}')
if not df_plot_filtered.empty:
    fig_bar_dynamic = px.bar(
        df_plot_filtered,
        x='Unidade Federativa',
        y=selected_y_label,
        title=f'{selected_display_title} por Unidade Federativa{title_sufix}',
        labels={'Unidade Federativa': 'Estado', selected_y_label: selected_y_label},
        color='Unidade Federativa',
        color_discrete_sequence=px.colors.qualitative.Set2
    )
    fig_bar_dynamic.update_layout(
        xaxis_tickangle=-35,
        showlegend=False,
        bargap=0.15,
        plot_bgcolor='white',
        font=dict(size=14)
    )
    # Formata√ß√£o para n√∫meros inteiros com separadores de milhares
    fig_bar_dynamic.update_traces(texttemplate='%{y:,.0f}', textposition='outside')
    st.plotly_chart(fig_bar_dynamic, use_container_width=True)
else:
    st.info(f"N√£o h√° dados para a regi√£o '{selected_region}' com os estados filtrados para a m√©trica '{selected_display_title}'.")

st.markdown('---')

# === Mapa Din√¢mico do Brasil por Estado ===
st.header(f'üó∫Ô∏è Mapa da Distribui√ß√£o de {selected_display_title} por Estado')

if geojson_data is not None and not df_plot_filtered.empty:
    fig_map_dynamic = px.choropleth_mapbox(
        df_plot_filtered,
        geojson=geojson_data,
        locations='Unidade Federativa_Normalized_for_map',
        featureidkey="properties.name_normalized",
        color=selected_y_label,
        color_continuous_scale="Viridis",
        range_color=(df_plot_filtered[selected_y_label].min(), df_plot_filtered[selected_y_label].max()),
        mapbox_style="carto-positron",
        zoom=3.5,
        center={"lat": -15.78, "lon": -47.93},
        opacity=0.7,
        labels={selected_y_label: selected_y_label},
        title=f'{selected_display_title} por Estado{title_sufix}'
    )
    fig_map_dynamic.update_layout(margin={"r":0,"t":0,"l":0,"b":0})
    st.plotly_chart(fig_map_dynamic, use_container_width=True)
else:
    st.info(f"N√£o foi poss√≠vel gerar o mapa para '{selected_display_title}'. Verifique se o GeoJSON foi carregado e se h√° dados filtrados.")

st.markdown('---')
# Os gr√°ficos dos 3 maiores, 3 do meio e 3 menores foram removidos a partir daqui.
