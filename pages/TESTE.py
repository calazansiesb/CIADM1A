import streamlit as st
import pandas as pd
import plotly.express as px
import requests # Importar para carregar o GeoJSON de forma mais robusta
import json # Usado em load_geojson, mas requests.json() geralmente j√° retorna o dicion√°rio
import unicodedata # Para normaliza√ß√£o de texto (remover acentos)
import re # Para normaliza√ß√£o de texto (opcional, mas bom para strip e lower)

# Substitua pela URL RAW correta do seu arquivo CSV no GitHub
GITHUB_CSV_URL = 'https://raw.githubusercontent.com/calazansiesb/CIADM1A/main/GALINACEOS.csv'

# URL para o arquivo GeoJSON dos estados do Brasil (exemplo)
# ATEN√á√ÉO: Esta URL pode n√£o ser permanente ou pode precisar de autentica√ß√£o dependendo da fonte.
# Recomenda-se baixar este arquivo e coloc√°-lo em seu reposit√≥rio ou encontrar uma fonte mais est√°vel.
GEOJSON_BR_STATES_URL = 'https://raw.githubusercontent.com/codeforamerica/click_that_hood/master/public/data/brazil-states.geojson'

# Fun√ß√£o auxiliar para normalizar nomes (remover acentos e converter para min√∫sculas)
def normalize_state_name(name):
    if isinstance(name, str):
        # Remove acentos e caracteres especiais, depois converte para min√∫sculas e remove espa√ßos extras
        normalized = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode('utf-8')
        return normalized.strip().lower()
    return name # Retorna o valor original se n√£o for string (ex: NaN)

@st.cache_data # Usar st.cache_data para cache de dados
def load_data(url):
    try:
        # Adicionei sep=';' e encoding='latin1' pois √© comum em CSVs brasileiros
        # Adicionei thousands='.' para tratar o ponto como separador de milhares na leitura de n√∫meros
        df = pd.read_csv(url, sep=';', encoding='latin1', thousands='.')
        return df
    except FileNotFoundError:
        st.error("Erro: O arquivo n√£o foi encontrado na URL especificada. Verifique se a URL est√° correta e o arquivo existe.")
        return pd.DataFrame()
    except pd.errors.EmptyDataError:
        st.error("Erro: O arquivo est√° vazio. N√£o h√° dados para processar.")
        return pd.DataFrame()
    except pd.errors.ParserError as e:
        st.error(f"Erro: O arquivo CSV n√£o p√¥de ser analisado. Verifique o delimitador (sep=';'), a codifica√ß√£o (encoding='latin1') ou os separadores de n√∫meros (thousands='.'). Detalhes: {e}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"Erro ao carregar dados do GitHub. Verifique a URL ou o formato do arquivo. Detalhes: {e}")
        return pd.DataFrame()

@st.cache_data # Cache para o GeoJSON
def load_geojson(url):
    try:
        response = requests.get(url)
        response.raise_for_status() # Lan√ßa um erro para status HTTP ruins (4xx ou 5xx)
        geojson_data = response.json()

        # Normaliza os nomes dos estados dentro do GeoJSON para facilitar o matching
        for feature in geojson_data['features']:
            if 'name' in feature['properties']:
                feature['properties']['name_original'] = feature['properties']['name'] # Mant√©m o nome original
                feature['properties']['name_normalized'] = normalize_state_name(feature['properties']['name'])
        return geojson_data
    except Exception as e:
        st.error(f"Erro ao carregar o arquivo GeoJSON: {e}. Verifique a URL ou o formato do arquivo.")
        return None

# Carregamento dos dados
df = load_data(GITHUB_CSV_URL)
geojson_data = load_geojson(GEOJSON_BR_STATES_URL)

if df.empty:
    st.warning("N√£o foi poss√≠vel carregar os dados. Verifique a URL e o conte√∫do do arquivo CSV.")
    st.stop() # Interrompe a execu√ß√£o se os dados n√£o puderem ser carregados

if geojson_data is None:
    st.warning("N√£o foi poss√≠vel carregar os dados geogr√°ficos. O mapa n√£o ser√° exibido.")
    # N√£o st.stop() aqui, para que o restante do app ainda funcione.


# Verifique as colunas do seu DataFrame.
if 'NOM_TERR' not in df.columns:
    st.error("A coluna 'NOM_TERR' n√£o foi encontrada no DataFrame. Por favor, verifique o nome da coluna no seu CSV.")
    st.stop()
if 'E_CRIA_GAL' not in df.columns:
    st.error("A coluna 'E_CRIA_GAL' n√£o foi encontrada no DataFrame. Por favor, verifique o nome da coluna no seu CSV.")
    st.stop()

# --- Normaliza√ß√£o da coluna NOM_TERR no DataFrame ---
# Isso garante que NOM_TERR e os nomes do GeoJSON estejam no mesmo formato para matching.
df['NOM_TERR_NORMALIZED'] = df['NOM_TERR'].apply(normalize_state_name)


st.header('üåé Distribui√ß√£o por Unidade Federativa')

# Lista oficial dos 26 estados + DF
estados_brasil = [
    'Acre', 'Alagoas', 'Amap√°', 'Amazonas', 'Bahia', 'Cear√°', 'Distrito Federal', 'Esp√≠rito Santo', 'Goi√°s',
    'Maranh√£o', 'Mato Grosso', 'Mato Grosso do Sul', 'Minas Gerais', 'Par√°', 'Para√≠ba', 'Paran√°', 'Pernambuco',
    'Piau√≠', 'Rio de Janeiro', 'Rio Grande do Norte', 'Rio Grande do Sul', 'Rond√¥nia', 'Roraima', 'Santa Catarina',
    'S√£o Paulo', 'Sergipe', 'Tocantins'
]

# Normaliza a lista de estados para a filtragem consistente
normalized_estados_brasil = [normalize_state_name(estado) for estado in estados_brasil]

# Mapeamento de estados para regi√µes
regioes_estados = {
    'Norte': ['Acre', 'Amap√°', 'Amazonas', 'Par√°', 'Rond√¥nia', 'Roraima', 'Tocantins'],
    'Nordeste': ['Alagoas', 'Bahia', 'Cear√°', 'Maranh√£o', 'Para√≠ba', 'Pernambuco', 'Piau√≠', 'Rio Grande do Norte', 'Sergipe'],
    'Centro-Oeste': ['Distrito Federal', 'Goi√°s', 'Mato Grosso', 'Mato Grosso do Sul'],
    'Sudeste': ['Esp√≠rito Santo', 'Minas Gerais', 'Rio de Janeiro', 'S√£o Paulo'],
    'Sul': ['Paran√°', 'Rio Grande do Sul', 'Santa Catarina']
}

# Inverter o dicion√°rio para mapear estado normalizado -> regi√£o
# Usa a lista `estados_brasil` original para mapear as regi√µes e ent√£o normaliza as chaves do dicion√°rio para uso posterior
estado_para_regiao_normalized = {normalize_state_name(estado): regiao for regiao, estados in regioes_estados.items() for estado in estados}

# Adicionar 'Regiao' ao DataFrame principal (usando o nome normalizado para o mapeamento de regi√£o)
df['Regiao'] = df['NOM_TERR_NORMALIZED'].map(estado_para_regiao_normalized)

# Filtrar apenas estados do Brasil (usando a coluna normalizada e a lista normalizada)
df_uf = df[df['NOM_TERR_NORMALIZED'].isin(normalized_estados_brasil)].copy()


# Calcular a SOMA de E_CRIA_GAL por UF (para o Brasil inteiro)
freq_estab_por_uf_total = df_uf.groupby('NOM_TERR')['E_CRIA_GAL'].sum().sort_values(ascending=False)
df_plot_total = freq_estab_por_uf_total.rename_axis('Unidade Federativa').reset_index(name='Quantidade de Galin√°ceos')

# === Seletor de Regi√£o para o Gr√°fico Din√¢mico ===
st.subheader('Selecione a Regi√£o para Exibir no Gr√°fico:')
regioes_disponiveis = ['Todas as Regi√µes'] + list(regioes_estados.keys())
selected_region = st.selectbox('Escolha uma regi√£o', regioes_disponiveis)

# Filtragem e c√°lculo da frequ√™ncia com base na sele√ß√£o
df_filtered_by_region = df_uf.copy() # Come√ßa com todos os estados do Brasil

title_sufix = ''
if selected_region != 'Todas as Regi√µes':
    estados_da_regiao = regioes_estados[selected_region]
    # Normaliza os estados da regi√£o para a filtragem
    normalized_estados_da_regiao = [normalize_state_name(e) for e in estados_da_regiao]
    df_filtered_by_region = df_filtered_by_region[df_filtered_by_region['NOM_TERR_NORMALIZED'].isin(normalized_estados_da_regiao)]
    title_sufix = f' na Regi√£o {selected_region}'

# Calcular a SOMA de E_CRIA_GAL APENAS para os estados filtrados
if not df_filtered_by_region.empty:
    freq_estab_por_uf_filtered = df_filtered_by_region.groupby('NOM_TERR')['E_CRIA_GAL'].sum().sort_values(ascending=False)
    df_plot_filtered = freq_estab_por_uf_filtered.rename_axis('Unidade Federativa').reset_index(name='Quantidade de Galin√°ceos')
    # Adiciona a coluna normalizada para o matching no mapa
    df_plot_filtered['Unidade Federativa_Normalized_for_map'] = df_plot_filtered['Unidade Federativa'].apply(normalize_state_name)
else:
    df_plot_filtered = pd.DataFrame(columns=['Unidade Federativa', 'Quantidade de Galin√°ceos', 'Unidade Federativa_Normalized_for_map']) # DataFrame vazio se n√£o houver dados


# === Gr√°fico Din√¢mico de Distribui√ß√£o por UF ===
st.subheader(f'Quantidade de Galin√°ceos por Estado{title_sufix}')
if not df_plot_filtered.empty:
    fig2 = px.bar(
        df_plot_filtered,
        x='Unidade Federativa',
        y='Quantidade de Galin√°ceos',
        title=f'Quantidade de Galin√°ceos por Unidade Federativa{title_sufix}',
        labels={'Unidade Federativa': 'Estado', 'Quantidade de Galin√°ceos': 'Quantidade de Galin√°ceos'},
        color='Unidade Federativa',
        color_discrete_sequence=px.colors.qualitative.Set2
    )
    fig2.update_layout(
        xaxis_tickangle=-35,
        showlegend=False,
        bargap=0.15,
        plot_bgcolor='white',
        font=dict(size=14)
    )
    # Adicionar o valor exato no topo de cada barra (formatado como inteiro com separador de milhares)
    fig2.update_traces(texttemplate='%{y:,.0f}', textposition='outside')
    st.plotly_chart(fig2, use_container_width=True)
else:
    st.info(f"N√£o h√° dados para a regi√£o '{selected_region}' com os estados filtrados.")

st.markdown('---')

# === Mapa do Brasil por Regi√£o/Estado ===
st.header('üó∫Ô∏è Mapa da Distribui√ß√£o de Galin√°ceos por Estado')

if geojson_data is not None and not df_plot_filtered.empty:
    # Use a coluna normalizada para o matching no GeoJSON
    fig_map = px.choropleth_mapbox(
        df_plot_filtered,
        geojson=geojson_data,
        locations='Unidade Federativa_Normalized_for_map', # Coluna no DataFrame com os nomes dos estados normalizados
        featureidkey="properties.name_normalized", # Caminho para o nome do estado normalizado no GeoJSON
        color='Quantidade de Galin√°ceos', # Coluna para colorir o mapa
        color_continuous_scale="Viridis", # Escala de cor
        range_color=(df_plot_filtered['Quantidade de Galin√°ceos'].min(), df_plot_filtered['Quantidade de Galin√°ceos'].max()),
        mapbox_style="carto-positron", # Estilo do mapa
        zoom=3.5, # Zoom inicial
        center={"lat": -15.78, "lon": -47.93}, # Centro do mapa (Bras√≠lia)
        opacity=0.7,
        labels={'Quantidade de Galin√°ceos':'Total de Galin√°ceos'},
        title=f'Quantidade de Galin√°ceos por Estado{title_sufix}'
    )
    fig_map.update_layout(margin={"r":0,"t":0,"l":0,"b":0})
    st.plotly_chart(fig_map, use_container_width=True)
else:
    st.info("N√£o foi poss√≠vel gerar o mapa. Verifique se o GeoJSON foi carregado e se h√° dados filtrados.")

st.markdown('---')

# Restante do c√≥digo para os gr√°ficos dos 3 maiores, 3 do meio e 3 menores (com altera√ß√µes de r√≥tulos)
st.header('An√°lise Detalhada da Quantidade de Galin√°ceos por Estado (Brasil)')

# Garantir que temos dados suficientes para essas an√°lises
if len(df_plot_total) >= 3:
    # Top 3 Maiores
    top_3 = df_plot_total.head(3)
    fig_top_3 = px.bar(
        top_3,
        x='Unidade Federativa',
        y='Quantidade de Galin√°ceos',
        title='Top 3 Maiores Estados em Quantidade de Galin√°ceos',
        labels={'Unidade Federativa': 'Estado', 'Quantidade de Galin√°ceos': 'Quantidade de Galin√°ceos'},
        color='Unidade Federativa',
        color_discrete_sequence=px.colors.qualitative.Plotly
    )
    fig_top_3.update_layout(xaxis_tickangle=-35, showlegend=False, plot_bgcolor='white', font=dict(size=14))
    fig_top_3.update_traces(texttemplate='%{y:,.0f}', textposition='outside')
    st.plotly_chart(fig_top_3, use_container_width=True)

    # 3 do Meio
    if len(df_plot_total) >= 6:
        middle_start = len(df_plot_total) // 2 - 1
        if middle_start < 0: middle_start = 0
        middle_3 = df_plot_total.iloc[middle_start : middle_start + 3]

        fig_middle_3 = px.bar(
            middle_3,
            x='Unidade Federativa',
            y='Quantidade de Galin√°ceos',
            title='3 Estados do Meio em Quantidade de Galin√°ceos',
            labels={'Unidade Federativa': 'Estado', 'Quantidade de Galin√°ceos': 'Quantidade de Galin√°ceos'},
            color='Unidade Federativa',
            color_discrete_sequence=px.colors.qualitative.D3
        )
        fig_middle_3.update_layout(xaxis_tickangle=-35, showlegend=False, plot_bgcolor='white', font=dict(size=14))
        fig_middle_3.update_traces(texttemplate='%{y:,.0f}', textposition='outside')
        st.plotly_chart(fig_middle_3, use_container_width=True)
    else:
        st.info("N√£o h√° estados suficientes para exibir os '3 do meio'. S√£o necess√°rios pelo menos 6 estados.")


    # 3 Menores
    bottom_3 = df_plot_total.tail(3)
    fig_bottom_3 = px.bar(
        bottom_3,
        x='Unidade Federativa',
        y='Quantidade de Galin√°ceos',
        title='Top 3 Menores Estados em Quantidade de Galin√°ceos',
        labels={'Unidade Federativa': 'Estado', 'Quantidade de Galin√°ceos': 'Quantidade de Galin√°ceos'},
        color='Unidade Federativa',
        color_discrete_sequence=px.colors.qualitative.G10
    )
    fig_bottom_3.update_layout(xaxis_tickangle=-35, showlegend=False, plot_bgcolor='white', font=dict(size=14))
    fig_bottom_3.update_traces(texttemplate='%{y:,.0f}', textposition='outside')
    st.plotly_chart(fig_bottom_3, use_container_width=True)

else:
    st.warning("N√£o h√° dados suficientes para gerar os gr√°ficos dos 3 maiores, 3 do meio e 3 menores estados.")
